"""
some functions that streamline working with h5 files generated by ARTIQ experiments
as well as some functions for plotting
"""

import numpy as np
import os
import h5py
import matplotlib as mpl
from matplotlib import pyplot as plt
from skimage.filters import threshold_otsu

results = "C:\\Networking Experiment\\artiq codes\\artiq-master\\results\\"

MHz = 1e6
kHz = 1e3
ms = 1e-3
us = 1e-6
V = 1

def binomial_err(n_loaded, retention):
    """returns the the binomial error for atom retention data given the number of atoms loaded"""
    return np.sqrt(n_loaded*retention*(1-retention))/n_loaded # sqrt(n*p*(1-p))/n

def eval_str_from_h5(h5_str):
    """a stupid way to evaluate python evaluable strings I saved as ARTIQ datasets"""
    return eval(str(np.array(h5_str))[2:-1])

def str_from_h5(h5_str):
    """a stupid way to read strings I saved as ARTIQ datasets"""
    return str(np.array(h5_str))[2:-1]

# from https://stackoverflow.com/questions/37765197/darken-or-lighten-a-color-in-matplotlib
def lighten_color(color, amount=0.5):
    """
    Lightens the given color by multiplying (1-luminosity) by the given amount.
    Input can be matplotlib color string, hex string, or RGB tuple.

    Examples:
    >> lighten_color('g', 0.3)
    >> lighten_color('#F034A3', 0.6)
    >> lighten_color((.3,.55,.1), 0.5)
    """
    import matplotlib.colors as mc
    import colorsys
    try:
        c = mc.cnames[color]
    except:
        c = color
    c = colorsys.rgb_to_hls(*mc.to_rgb(c))
    return colorsys.hls_to_rgb(c[0], 1 - amount * (1 - c[1]), c[2])

def get_files_by_criteria(date_filters,name_filters,condition,start_dir=results,include_path=True,print_filenames=False):
    file_list = []
    for root, dirs, files in os.walk(start_dir,topdown=False):
        for name in files:
            if True in set([x in root for x in date_filters]):
                name_filter_set = set([x in name for x in name_filters])
                if len(name_filter_set) == 1 and True in name_filter_set:
                    filename = os.path.join(root, name)
                    try:
                        h5py.File(filename)
                        if condition(filename):
                            if not include_path:
                                filename = name
                                if print_filenames:
                                    print(filename)
                            file_list.append(filename)
                    except OSError:
                        print(f"skipping {filename}, which is corrupt")
    return file_list

def h5_archive_and_datasets_to_locals(f, parent_locals, quiet=False):
    """
    Adds the values in archive and datasets fields of an h5 file to your current scope's local variables

    This allows for using the h5's data by name in your code without any additional ceremony.

    Arguments:
        f: the h5 file object
        parent_locals: set this equal to locals() in your code
        quiet: False by default, will print out any fields that failed to be cast to python types. 
            if True, these messages will not be printed.
    Returns:
        nothing is returned
    """
    for data_level in ['archive','datasets']:
        for key in f[data_level].keys():
            try:
                shape = f[data_level][key].shape
                dtype = f[data_level][key].dtype
                raw_value = f[data_level][key][()]
                if shape == (): # scalar
                    if dtype == object:
                        if type(raw_value) == bytes:
                            
                            try:
                                value = str_from_h5(f[data_level][key])
                            except:
                                raise
                        else:
                            try:
                                eval(f[data_level][key][()])
                            except:
                                raise
                    else:
                        value = f[data_level][key][()]
                    # print(key, shape, dtype, value)
                    # locals().update({key: value})
                else:
                    # print(key, shape, dtype, value)
                    value = f[data_level][key][:]
                    # locals().update({key: value})

                if key == 'SPCM0_RO1' or key == 'SPCM0_RO2' or key == 'SPCM1_RO1' or key == 'SPCM1_RO2' or key == 'BothSPCMs_RO2':
                    value = value[1:]
                
                parent_locals.update({key: value})
            except:
                if not quiet:
                    print("oops in:",data_level, key, shape, dtype, value)

def print_h5_archive_and_datasets(f, scalars_only=True, quiet=False):
    """
    Adds the values in archive and datasets fields of an h5 file to your current scope's local variables

    This allows for using the h5's data by name in your code without any additional ceremony.

    Arguments:
        f: the h5 file object
        parent_locals: set this equal to locals() in your code
        quiet: False by default, will print out any fields that failed to be cast to python types. 
            if True, these messages will not be printed.
    Returns:
        nothing is returned
    """
    for data_level in ['archive','datasets']:
        for key in f[data_level].keys():
            try:
                shape = f[data_level][key].shape
                dtype = f[data_level][key].dtype
                raw_value = f[data_level][key][()]
                if shape == (): # scalar
                    if dtype == object:
                        if type(raw_value) == bytes:
                            
                            try:
                                value = str_from_h5(f[data_level][key])
                            except:
                                raise
                        else:
                            try:
                                eval(f[data_level][key][()])
                            except:
                                raise
                    else:
                        value = f[data_level][key][()]
                    # print(key, shape, dtype, value)
                    # locals().update({key: value})
                else:
                    # print(key, shape, dtype, value)
                    value = f[data_level][key][:]
                    # locals().update({key: value})

                if key == 'SPCM0_RO1' or key == 'SPCM0_RO2' or key == 'SPCM1_RO1' or key == 'SPCM1_RO2' or key == 'BothSPCMs_RO2':
                    value = value[1:]

                if scalars_only:
                    try:
                        len(value)
                    except:
                        print(f"{key} = {value}")
                else:
                    print(f"{key} = {value}")
            except:
                if not quiet:
                    print("oops in:",data_level, key, shape, dtype, value)

def get_loading_and_retention(BothSPCMs_RO1, BothSPCMs_RO2, measurements, iterations, cutoff1, cutoff2=None, otsu=False):
        """
        Returns retention, loading rate, and number of atoms loaded for each experiment iteration.
        
        cutoff1 and cutoff2 (optional) are the atom loading thresholds in units counts.

        otsu: if True, will recompute loading using Otsu threshold if initial loading rate calculation > 0.3
        """
        
        if cutoff2 is None:
            cutoff2 = cutoff1
        
        retention_array = np.zeros(iterations)
        loading_rate_array = np.zeros(iterations)
        n_atoms_loaded_array = np.zeros(iterations)
                
        for i in range(iterations):
            shot1 = BothSPCMs_RO1[i*measurements:(i+1)*measurements]
            shot2 = BothSPCMs_RO2[i*measurements:(i+1)*measurements]

            if len(shot1) == 0:
                print(f"iteration {i}, no measurements")
                break
            
            atoms_loaded = [x > cutoff1 for x in shot1] ### results in [true, False] array
            n_atoms_loaded = sum(atoms_loaded)
            loading_fraction = n_atoms_loaded/len(shot1)
            if loading_fraction > 0.3 and otsu:  # apparent very low rate loading might just be wrongly classified background
                cutoff1 = cutoff2 = threshold_otsu(shot1)
                atoms_loaded = [x > cutoff1 for x in shot1]
                n_atoms_loaded = sum(atoms_loaded)
                loading_fraction = n_atoms_loaded / len(shot1)
            
            atoms_retained = [x > cutoff2 and y for x,y in zip(shot2, atoms_loaded)]
            retention_fraction = 0 if not n_atoms_loaded > 0 else sum(atoms_retained)/n_atoms_loaded
            loading_rate_array[i] = n_atoms_loaded/measurements
            n_atoms_loaded_array[i] = n_atoms_loaded
            retention_array[i] = retention_fraction
        return retention_array, loading_rate_array, n_atoms_loaded_array

def compute_cost(retention, loading, cost_function):
    if cost_function == 'atom_blowaway_cost':
        cost = -100*(1-retention)
    elif cost_function == 'atom_retention_cost':
        cost = -100*retention
    elif cost_function == 'atom_loading_with_otsu_threshold_cost' or cost_function == 'atom_loading_cost':
        cost = -100*loading
    else:
        print(f"oops, you need to compute the cost here according to {cost_function}!")
        raise NotImplementedError

# def plot_retention_and_histograms(experiment_name, SPCM0_RO1, SPCM0_RO2, cutoff1,cutoff2,n_measurements, scan_variable1_name, scan_variable2_name, scan_sequence1,scan_sequence2, showloading=False, showhist=True):
#     """
#     Plot retention and readout histogram(s) for a GeneralVariableScan
#     """

#     iterations = len(scan_sequence1)*len(scan_sequence2)
    
#     if scan_variable2_name != '':
#         scan_is_2D = True
#     else:
#         scan_sequence2 = np.zeros(1)
#         scan_is_2D = False

#     retention_array = np.zeros(iterations)
#     loading_rate_array = np.zeros(iterations)
#     n_atoms_loaded_array = np.zeros(iterations)
#     shape = (len(scan_sequence2),len(scan_sequence1))
#     loading_rate_raveled = np.reshape(loading_rate_array,shape,order='F') # rows have constant variable2
#     n_atoms_loaded_raveled = np.reshape(n_atoms_loaded_array,shape,order='F') # rows have constant variable2
#     retention_raveled = np.reshape(retention_array,shape,order='F') # rows have constant variable2
    
#     ncols = len(scan_sequence2)
#     nrows = len(scan_sequence1)
    
#     dvar1 = abs(scan_sequence1[1]-scan_sequence1[0])
#     if scan_is_2D:
#         dvar2 = abs(scan_sequence2[1]-scan_sequence2[0])

#     if showhist:
#         fig,axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(10,7))
#         for i, ax in enumerate(axes.flat):
#             shot1 = SPCM0_RO1[i*n_measurements:(i+1)*n_measurements]
#             shot2 = SPCM0_RO2[i*n_measurements:(i+1)*n_measurements]
#             ax.hist(shot1,bins=30, facecolor=(0.0, 0.5, 1, 1),label='shot 1')
#             ax.hist(shot2,bins=30, facecolor=(1.0, 0.0, 0.0, 0.1),label='shot 2', edgecolor=(0, 0, 0, 1), linestyle='-')
#             ax.set_title(f"retention={retention_array[i]:.2f}\nloading rate={loading_rate_array[i]:.2f}",fontsize=8)
#             # ax.set_ylabel("occurences")
#             # ax.set_xlabel("photons")
#             ax.set_xticks([])
#             ax.set_yticks([])
#         if scan_is_2D: # todo
#             axes.flat[ncols-1].legend(loc=(1.05,-nrows/2))
#             [axes[-1,ncols-i-1].set_xlabel(var2) for i,var2 in enumerate(scan_sequence2)]
#             [axes[nrows-i-1,0].set_ylabel(var1,rotation=0) for i,var1 in enumerate(scan_sequence1)]
#             [axes[nrows-i-1,0].yaxis.set_label_coords(-0.2,0.4) for i in range(nrows)]
#         fig.text(0.45,-0.5, scan_variable2_name)
#         fig.text(0.05,0.35, scan_variable1_name,rotation=90)
#         plt.subplots_adjust(bottom=-0.4)
#         plt.show()
    
#     if scan_is_2D:
#         # plot a colormap of the retention
#         fig,ax = plt.subplots()
#         cax=ax.imshow(retention_raveled,cmap='afmhot',interpolation='none',
#                       extent=[scan_sequence1[0]-dvar1/2,scan_sequence1[-1]+dvar1/2,scan_sequence2[-1]+dvar2/2,scan_sequence2[0]-dvar2/2])
#         im = ax.get_images()
#         extent =  im[0].get_extent()
#         # plt.setp(ax.spines.values(), linewidth=0.1)
#         ax.set_aspect(abs((extent[1]-extent[0])/(extent[3]-extent[2])))
#         ax.set_xticks(scan_sequence1)
#         ax.set_yticks(scan_sequence2_name)
#         ax.set_title(experiment_name_name)
#         ax.set_xlabel(scan_variable1_name)
#         ax.set_ylabel(scan_variable2_name)
#         # ax.tick_params(axis='both', labelsize=10)
#         fig.colorbar(cax)
#         # plt.clim(0,1)
#         plt.show()

#     # plot a retention curve vs variable 1 for each variable 2 value
#     cmap = mpl.colormaps['inferno']
#     for i, retention, n_loaded, var2 in zip(range(len(scan_sequence2)),retention_raveled, n_atoms_loaded_raveled, scan_sequence2):
#         plt.plot(scan_sequence1, retention,color=cmap(i/len(scan_sequence2)),linestyle='--')
#         plt.scatter(scan_sequence1, retention,color=cmap(i/len(scan_sequence2)),label=scan_variable2_name+"="+str(var2))
#         errs = [1/np.sqrt(n) if n > 0 else np.inf for n in n_loaded]
#         plt.errorbar(scan_sequence1, retention, errs, ls='none',color=cmap(i/len(scan_sequence2)))
#         plt.ylim((0,1))
#         plt.xlabel(scan_variable1_name)
#         plt.ylabel("retention")
#         plt.legend()
#         plt.title(experiment_name)
#         plt.show()
    
#     if showloading:
#         for i, loading, n_loaded, var2 in zip(range(len(scan_sequence2)),loading_rate_raveled, n_atoms_loaded_raveled, scan_sequence2):
#             plt.plot(scan_sequence1, loading,color=cmap(i/len(scan_sequence2)),linestyle='--')
#             plt.scatter(scan_sequence1, loading,color=cmap(i/len(scan_sequence2)),label=scan_variable2_name+"="+str(var2))
#             errs = [1/np.sqrt(n) if n > 0 else np.inf for n in n_loaded]
#             plt.errorbar(scan_sequence1, loading, errs, ls='none',color=cmap(i/len(scan_sequence2)))
#             plt.ylim((0,1))
#             plt.xlabel(scan_variable1_name)
#             plt.ylabel("loading rate")
#             plt.legend()
#             plt.title(experiment_name)
#             plt.show()